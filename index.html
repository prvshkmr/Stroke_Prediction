<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Composite Sketch+Text Queries for Retrieving Objects</title>
    <style>
        /* Add your CSS styles here */
    </style>
</head>
<body>
    <header>
        <h1>Composite Sketch+Text Queries for Retrieving Objects</h1>
    </header>
    <section>
        <h2>Abstract</h2>
        <p>Non-native speakers with limited vocabulary often struggle to name specific objects despite being able to visualize them clearly, e.g., people outside Australia searching for ‘numbats.’ Further, users may want to search for such elusive objects with difficult-to-sketch interactions, e.g., “numbat digging in the ground.” In such common but complex situations, users desire a search interface that accepts composite multimodal queries comprising hand-drawn sketches of “difficult-to-name but easy-to-draw” objects along with text describing “difficult-to-sketch but easy-to-verbalize” object’s attributes or interaction with the scene. This novel problem statement is distinctly different from the previously well-researched TBIR (text-based image retrieval) and SBIR (sketch-based image retrieval) problems. To study this under-explored task, we curate a dataset, CSTBIR (Composite Sketch+Text Based Image Retrieval), consisting of ∼2M queries and 108K natural scene images. Further, as a solution to this problem, we propose a pretrained multimodal transformer-based baseline, STNET (Sketch+Text Network), that uses a hand-drawn sketch to localize relevant objects in the natural scene image, and encodes the text and image to perform image retrieval. In addition to contrastive learning, we propose multiple train- ing objectives that improve the performance of our model. Extensive experiments show that our proposed method outperforms several state-of-the-art retrieval methods for text-only, sketch-only, as well as composite query modalities.</p>
        <h3>Keywords</h3>
        <p>sketch+text-based image retrieval, cross-modal retrieval, image retrieval, SBIR, CSTBIR</p>
    </section>
    <section>
        <h2>The CSTBIR Problem</h2>
        <p>Composite Sketch+Text Based Image Retrieval: A user wants to search “Numbat digging in the ground” but does not know the word “numbat”, and the interaction “digging in the ground” is not easy to sketch. Thus, the user may use a hand-drawn sketch of "numbat" along with the text "digging in the ground" to retrieve the desired images.</p>
    </section>
    <section>
        <h2>Sketches in CSTBIR</h2>
        <p>Examples of sketches.</p>
    </section>
    <section>
        <h2>Short Talk</h2>
        <p>Paper: Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions, Prajwal Gatti, Kshitij Gopal Parikh, Drithi Prasanna Paul, Manish Gupta, Anand Mishra.</p>
        <p>[<a href="#">paper</a>] [<a href="#">appendix</a>]</p>
    </section>
    <section>
        <h2>View related works from our group</h2>
        <ul>
            <li>Query-guided Attention in Vision Transformers for Localizing Objects Using a Single Sketch [<a href="#">paper</a>] Authors: Aditay Tripathi, Anand Mishra, Anirban Chakraborty. WACV 2024</li>
            <li>Multimodal Query-guided Object Localization [<a href="#">paper</a>] Authors: Aditay Tripathi, Rajath R. Dani, Anand Mishra, Anirban Chakraborty. Multimedia Tools and Applications 2023</li>
            <li>Sketch-Guided Object Localization in Natural Images [<a href="#">paper</a>] Authors: Aditay Tripathi, Rajath R Dani, Anand Mishra, Anirban Chakraborty. ECCV 2020</li>
            <li>Deep Embedding using Bayesian Risk Minimization with Application to Sketch Recognition [<a href="#">paper</a>] Authors: Anand Mishra, Ajeet Kumar Singh. ACCV 2018</li>
        </ul>
    </section>
    <section>
        <h2>Bibtex</h2>
        <pre>
@InProceedings{cstbir2024aaai,
    author    = {Gatti, Prajwal and Parikh, Kshitij Gopal and Paul, Dhriti Prasanna and Gupta, Manish and Mishra, Anand},
    title     = {Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions},
    booktitle = {AAAI},
    year      = {2024},
}
        </pre>
    </section>
    <section>
        <h2>Team</h2>
        <ul>
            <li><img src="team_image_url" alt="Prajwal Gatti"> Prajwal Gatti</li>
            <li><img src="team_image_url" alt="Kshitij Parikh"> Kshitij Parikh</li>
            <li><img src="team_image_url" alt="Dhriti Prasanna Paul"> Dhriti Prasanna Paul</li>
            <li><img src="team_image_url" alt="Manish Gupta"> Manish Gupta</li>
            <li><img src="team_image_url" alt="Anand Mishra"> Anand Mishra</li>
        </ul>
    </section>
    <section>
        <h2>Acknowledgment</h2>
        <p>This work is supported by the Startup Research Grant from the Science and Engineering Research Board (SERB), Department of Science and Technology, Government of India (Grant No: SRG/2021/001948).</p>
    </section>
    <section>
        <h2>Contact</h2>
        <p>For questions, please contact Prajwal Gatti or raise an issue on GitHub. Copyright © IIT Jodhpur</p>
    </section>
</body>
</html>
